{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning on Stock Trading (CS230 Milestone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "Author: Bicheng Wang, Xinyi Zhang   \n",
    "Email: bichengw@stanford.edu, xyzh@stanford.edu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profitable automated trading strategy plays a critical role to investment companies and hedge funds. Given that the stock market is dynamic and complex, it is challenging to design such a strategy. The project proposes to use a deep reinforcement learning framework to learn a profitable stock trading mechanism, with the goal to optimize the cumulative return and Alpha.\n",
    "It would select S\\&P 500 Index along with its top 20 market capitalization stocks as our trading stock pool.\n",
    "The input to our algorithm is the market price for these stocks, remaining balance, current portfolio and technical indicator statistics. The model agent output is a series of trading actions among stocks. \n",
    "The available trading action options are: sell, buy and hold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose 20 stocks with top performance in the S\\&500 index (exclude companies IPO after 2000) from 2000 to 2020 as our dataset. The original data is fetched from Yahoo Finance API. Each dataset row is comprised of date, open price, high price, low price, close price, volumn, ticker symbol, # day in a week. The dataset has 105680 rows in total. We split the dataset into training and test on a 90/10 basis. The training set contains data ranging from 2000 to 2018, while the test set contains data ranging from 2019 to 2020. The first 5 rows of the dataset are presented as follows:\n",
    "![](img/original_dataset_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 337-dimensional vector consists of 17 parts of information to represent the state space of multiple stocks trading environment: \n",
    "***[b, p, s, macd, boll_ub, boll_lb, rsi_10, rsi_20, cci_10, cci_20, dx_30, close_20_sma, close_60_sma, close_120_sma, close_20_ema, close_60_ema, close_120_ema]***. \n",
    "Each component is defined as follows:\n",
    "- **b**: available balance \n",
    "- **p**: close price of each stock\n",
    "- **s**: shares owned of each stock\n",
    "- **macd**: Moving Average Convergence Divergence of each stock\n",
    "- **boll_ub**: Upper Bollinger Bands of each stock\n",
    "- **boll_lb**: Lower Bollinger Bands of each stock\n",
    "- **rsi_x**: Relative Strength Index of each stock, calculated using close price\n",
    "- **cci_x**: Commodity Channel Index of each stock, calculated using high, low and close price\n",
    "- **dx**: Directional Movement Index of each stock\n",
    "- **close_x_sma**: Simple Moving Average of each stock\n",
    "- **close_x_ema**: Exponential Moving Average of each stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single stock, the action space is defined as *{-k. ..., -1, 0, 1, ..., k}*, where *k* and *-k* represents the number of shares we can buy and sell. A predefined parameter is set as the maximum amount of shares for each buying/selling action. Therefore, a 21-dimensional vector will be used to represent the action space. It will be normalized to [-1, 1] since the RL algorithms A2C and PPO define the policy directly on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reward Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reward function will be defined as the change of portfolio value when action ***a*** is taken at state ***s*** and arriving at a new state ***s'***. The goal is to design a trading strategy to maximize the change of the portfolio value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//TODO(bicheng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add early stage results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method  | Training Period | Evaluation Period |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| Baseline|![](img/training_spy_performance.jpg)|![](img/evaluation_spy_performance.jpg)|\n",
    "| A2C | ![](img/training_a2c_performance.jpg) | ![](img/evaluation_a2c_performance.jpg) |\n",
    "| PPO | ![](img/training_ppo_performance.jpg) | ![](img/evaluation_ppo_performance.jpg) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method  | Training Period | Evaluation Period |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| A2C | ![](img/training_a2c_backtest1.jpg) | ![](img/evaluation_a2c_backtest1.jpg) |\n",
    "| PPO | ![](img/training_ppo_backtest1.jpg) | ![](img/evaluation_ppo_backtest1.jpg) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method  | Training Period | Evaluation Period |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| A2C | ![](img/training_a2c_backtest2.jpg) | ![](img/evaluation_a2c_backtest2.jpg) |\n",
    "| PPO | ![](img/training_ppo_backtest2.jpg) | ![](img/evaluation_ppo_backtest2.jpg) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect to improve the current implementation by:\n",
    "- Add more technical indicators\n",
    "- Try a few more RL models like SAC, TD3\n",
    "- Change the usage of dataset: currently statistics of different stocks on the same trading day are merged to a single data point, we plan to change the dataset usage so that statistics of a single stock on a trading day can be treated as a single data point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
